{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# drive/MyDrive/Colab Notebooks/.."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I3rLD6BvvRsd",
        "outputId": "802de9ad-5017-458f-f358-2bb990443018"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Dataset\n",
        "load 'amazon_reviews' dataset and discover it"
      ],
      "metadata": {
        "id": "w0oW71OrvdxO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "HBaxS1QiwBZ4"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "amazon_reviews = pd.read_csv('drive/MyDrive/Colab Notebooks/amazon_reviews.csv')"
      ],
      "metadata": {
        "id": "Yu4SAhDHvd-D"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Amazon Reviews Data Head:')\n",
        "print('-------------------------')\n",
        "print(amazon_reviews.head().to_markdown(tablefmt=\"github\", index=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iL1reBcEvtNo",
        "outputId": "e5829376-17f9-489b-ef7a-e9ebd878af66"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Amazon Reviews Data Head:\n",
            "-------------------------\n",
            "| sentiments   | cleaned_review                                                                                                                                                                                                                                                                                                                                                                                                                                                              |   cleaned_review_length |   review_score |\n",
            "|--------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|-------------------------|----------------|\n",
            "| positive     | i wish would have gotten one earlier love it and it makes working in my laptop so much easier                                                                                                                                                                                                                                                                                                                                                                               |                      19 |              5 |\n",
            "| neutral      | i ve learned this lesson again open the package and use the product right away ordered this mouse in august as my travel mouse and just packed it away in my bag now ve been visiting family in the pnw since mid september the mouse took charge and worked fine for couple of weeks after recharged the mouse it worked for day or two and then ceased to function the optical light will flash once when turned on then nothing of course the return window is well past |                      88 |              1 |\n",
            "| neutral      | it is so slow and lags find better option                                                                                                                                                                                                                                                                                                                                                                                                                                   |                       9 |              2 |\n",
            "| neutral      | roller ball stopped working within months of minimal use piece of junk                                                                                                                                                                                                                                                                                                                                                                                                      |                      12 |              1 |\n",
            "| neutral      | i like the color and size but it few days out of the return period and it will not hold charge                                                                                                                                                                                                                                                                                                                                                                              |                      21 |              1 |\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"amazon reviews information:\")\n",
        "print(amazon_reviews.info())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gdBTcD4Pv3pK",
        "outputId": "aa06dc63-6eab-4705-c203-7d391a271590"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "amazon reviews information:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 17340 entries, 0 to 17339\n",
            "Data columns (total 4 columns):\n",
            " #   Column                 Non-Null Count  Dtype  \n",
            "---  ------                 --------------  -----  \n",
            " 0   sentiments             17340 non-null  object \n",
            " 1   cleaned_review         17337 non-null  object \n",
            " 2   cleaned_review_length  17340 non-null  int64  \n",
            " 3   review_score           17340 non-null  float64\n",
            "dtypes: float64(1), int64(1), object(2)\n",
            "memory usage: 542.0+ KB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(amazon_reviews['sentiments'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8IkfrM8OwP_A",
        "outputId": "44dd8ea3-53e4-4acd-b63f-eb81832b81fc"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sentiments\n",
            "positive    9503\n",
            "neutral     6303\n",
            "negative    1534\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get max review length to use it in the padding\n",
        "max_review_length = amazon_reviews['cleaned_review_length'].max()\n",
        "print(f'max cleaned review length: {max_review_length}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JrGDhNMfwWi3",
        "outputId": "955245c0-5a1a-4784-ce5f-24a29dee20f7"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max cleaned review length: 571\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove rows where the 'cleaned_review_length' column is 0\n",
        "print(f\"amazon reviews shape before remove 0 length: {amazon_reviews.shape}\")\n",
        "amazon_reviews = amazon_reviews[amazon_reviews['cleaned_review_length'] != 0]\n",
        "print(f\"amazon reviews shape before after 0 length: {amazon_reviews.shape}\")"
      ],
      "metadata": {
        "id": "RviacdlPyvMp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f34202c9-b131-4cb0-b8f0-ac3b6c717cb0"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "amazon reviews shape before remove 0 length: (17340, 4)\n",
            "amazon reviews shape before after 0 length: (17321, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Pre-processing (if needed)\n",
        "to clean your data and provide a valid dataset for the models to be trained, like removing stopwords using NLTK\n",
        "\n"
      ],
      "metadata": {
        "id": "qVVQcfyGvJLM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "OJdST44TwuMZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51987e1d-91a0-4ef7-8d22-76bd4e484514"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "keHsG7_ducvK"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import numpy as np\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "we add **'data cleaning'** to ensure that data will come from the input part (bonus part) will be cleaned as our amazon reviews data.\n",
        "\n"
      ],
      "metadata": {
        "id": "b7dkXEaaCoy7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def text_cleaning(text):\n",
        "    # remove email address\n",
        "    text = re.sub(r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Za-z]{2,}\\b', '', text)\n",
        "    # remove puctuations and numbers\n",
        "    text = re.sub(r'[^A-Za-z\\s]', ' ', text)\n",
        "\n",
        "    return text"
      ],
      "metadata": {
        "id": "l3pY6XWD74N1"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocessing(text):\n",
        "    # perform text cleaning (removing irrelevant words, symbols, etc.)\n",
        "    clean_text = text_cleaning(text)\n",
        "    # tokenization for lowercase words\n",
        "    text_tokens = word_tokenize(clean_text.lower())\n",
        "    # remove all stopwords\n",
        "    stopwrds = set(stopwords.words('english'))\n",
        "    text_rmstop = [i for i in text_tokens if i not in stopwrds]\n",
        "    # limmatize all words\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    text_lemm = [lemmatizer.lemmatize(w) for w in text_rmstop]\n",
        "\n",
        "    return ' '.join(text_lemm)"
      ],
      "metadata": {
        "id": "lp7vyLogwx2G"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# apply preprocessing step\n",
        "amazon_reviews['cleaned_review'] = amazon_reviews['cleaned_review'] .apply(preprocessing)"
      ],
      "metadata": {
        "id": "HZ_mM0alw2iS"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Amazon Reviews Data Head after Preprocessing:')\n",
        "print('---------------------------------------------')\n",
        "print(amazon_reviews.head().to_markdown(tablefmt=\"github\", index=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k5mf5NZVw7GD",
        "outputId": "bf5636a9-8da3-4dda-89e5-4f1cebcb25a0"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Amazon Reviews Data Head after Preprocessing:\n",
            "---------------------------------------------\n",
            "| sentiments   | cleaned_review                                                                                                                                                                                                                                                                                          |   cleaned_review_length |   review_score |\n",
            "|--------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|-------------------------|----------------|\n",
            "| positive     | wish would gotten one earlier love make working laptop much easier                                                                                                                                                                                                                                      |                      19 |              5 |\n",
            "| neutral      | learned lesson open package use product right away ordered mouse august travel mouse packed away bag visiting family pnw since mid september mouse took charge worked fine couple week recharged mouse worked day two ceased function optical light flash turned nothing course return window well past |                      88 |              1 |\n",
            "| neutral      | slow lag find better option                                                                                                                                                                                                                                                                             |                       9 |              2 |\n",
            "| neutral      | roller ball stopped working within month minimal use piece junk                                                                                                                                                                                                                                         |                      12 |              1 |\n",
            "| neutral      | like color size day return period hold charge                                                                                                                                                                                                                                                           |                      21 |              1 |\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " # Data Splitting\n",
        " apply data splitting for your; 80% as training set and 20% as\n",
        " validation set."
      ],
      "metadata": {
        "id": "pbhwzf8JzvSU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "fHtrVmSA0Pt5"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# map the sentiments to numbers to be used in the models\n",
        "amazon_reviews['sentiments'] = amazon_reviews['sentiments'].map({'negative': 0, 'neutral': 1, 'positive': 2})"
      ],
      "metadata": {
        "id": "yq0ZjSNm0cSl"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data\n",
        "def data_splitting(training_ratio):\n",
        "    return train_test_split(amazon_reviews['cleaned_review'], amazon_reviews['sentiments'], train_size=training_ratio, random_state=42)\n",
        "\n",
        "x_train, x_validation, y_train, y_validation = data_splitting(0.8)"
      ],
      "metadata": {
        "id": "vDR2rvL9z92C"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " # Word Embedding\n",
        " build your vocabulary by extracting and indexing unique words,\n",
        " convert each review to a sequence of indices, then apply sequence padding to\n",
        " have all sequences of the same length in preparation for input to the embedding\n",
        " layer."
      ],
      "metadata": {
        "id": "zil_WvCuz7bI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "id": "e8Dy-RtCz-Wm"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_tokinizer(x_train):\n",
        "  tokenizer = Tokenizer()\n",
        "  tokenizer.fit_on_texts(x_train)\n",
        "\n",
        "  vocab_size = len(tokenizer.word_index) + 1\n",
        "\n",
        "  return tokenizer, vocab_size\n",
        "\n",
        "def build_vocab(tokenizer, text, padding_length):\n",
        "  # Convert text to sequences\n",
        "  text_seq = tokenizer.texts_to_sequences(text)\n",
        "  # Padding sequences\n",
        "  text_pad = pad_sequences(text_seq, maxlen=padding_length)\n",
        "\n",
        "  return text_pad"
      ],
      "metadata": {
        "id": "bInJARMW1esx"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer, vocab_size = train_tokinizer(x_train)\n",
        "x_train_pad, x_validation_pad= build_vocab(tokenizer, x_train, max_review_length), build_vocab(tokenizer, x_validation, max_review_length)"
      ],
      "metadata": {
        "id": "iSnIyGuVE6JK"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Shape of x_train:', x_train_pad.shape)\n",
        "print('Shape of x_validation:', x_validation_pad.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ymmr5b1R2FVV",
        "outputId": "ef05a08d-dfd0-4713-d41e-18339b337ccc"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of x_train: (13856, 571)\n",
            "Shape of x_validation: (3465, 571)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Vocabulary size: {vocab_size} unique tokens.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gvQ3JAVs2PDs",
        "outputId": "09788484-fd8f-4360-a780-91b56e1d27fb"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary size: 7846 unique tokens.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " # Model Training\n",
        " You will train two models simpleRNN and LSTM and print the\n",
        " accuracy for each model on testing data."
      ],
      "metadata": {
        "id": "hXq68Y8Cz8qa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Simple RNN model"
      ],
      "metadata": {
        "id": "3B63kV6G-1qO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, SimpleRNN, LSTM, Dense, SpatialDropout1D"
      ],
      "metadata": {
        "id": "fKrEGaHp3w23"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_rnn_model(vocab_size, embedding_dim, padding_length, units):\n",
        "    model = Sequential([\n",
        "      # Embedding layer to convert words to vectors of fixed size (embedding_dim)\n",
        "      Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=padding_length),\n",
        "      # recurrent layer with 'units' hidden neurans\n",
        "      SimpleRNN(units), # default activation='tanh'\n",
        "      Dense(3, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "bfnB4olVz_I3"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train RNN model\n",
        "rnn_model = create_rnn_model(vocab_size, 200, max_review_length, 32)\n",
        "rnn_model.fit(x_train_pad, y_train, epochs=5, batch_size=64, validation_data=(x_validation_pad, y_validation))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FCOqMeGV3vVz",
        "outputId": "b1199fe4-2e16-413a-a54d-577745d0198b"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "217/217 [==============================] - 70s 319ms/step - loss: 0.7119 - accuracy: 0.6863 - val_loss: 0.5023 - val_accuracy: 0.8075\n",
            "Epoch 2/5\n",
            "217/217 [==============================] - 65s 300ms/step - loss: 0.3181 - accuracy: 0.8915 - val_loss: 0.4068 - val_accuracy: 0.8522\n",
            "Epoch 3/5\n",
            "217/217 [==============================] - 64s 295ms/step - loss: 0.1464 - accuracy: 0.9580 - val_loss: 0.4184 - val_accuracy: 0.8580\n",
            "Epoch 4/5\n",
            "217/217 [==============================] - 68s 312ms/step - loss: 0.0895 - accuracy: 0.9760 - val_loss: 0.4560 - val_accuracy: 0.8563\n",
            "Epoch 5/5\n",
            "217/217 [==============================] - 69s 316ms/step - loss: 0.0550 - accuracy: 0.9871 - val_loss: 0.4798 - val_accuracy: 0.8603\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7d5588ca2080>"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(rnn_model.summary())"
      ],
      "metadata": {
        "id": "XahVR8hC8_s9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "173f7bee-5802-4075-b44f-7f3248014f5a"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_4 (Embedding)     (None, 571, 200)          1569200   \n",
            "                                                                 \n",
            " simple_rnn_3 (SimpleRNN)    (None, 32)                7456      \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 3)                 99        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1576755 (6.01 MB)\n",
            "Trainable params: 1576755 (6.01 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate RNN\n",
        "rnn_loss, rnn_accuracy = rnn_model.evaluate(x_validation_pad, y_validation)\n",
        "print(f'RNN Accuracy: {rnn_accuracy*100.0:.2f}%')"
      ],
      "metadata": {
        "id": "q3yymL1m3-tW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c534c7e0-4094-4dfe-8913-e6e1a0306b7c"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "109/109 [==============================] - 7s 59ms/step - loss: 0.4798 - accuracy: 0.8603\n",
            "RNN Accuracy: 86.03%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. LSTM model"
      ],
      "metadata": {
        "id": "-V1SPVrU-8CX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_lstm_model(vocab_size, embedding_dim, padding_length, units, dropout):\n",
        "    model = Sequential([\n",
        "        # Embedding layer to convert words to vectors of fixed size (embedding_dim)\n",
        "        Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=padding_length),\n",
        "        # SpatialDropout1D layer applies random dropout to the input (1D feature vectors) of the LSTM layer to prevent overfitting\n",
        "        SpatialDropout1D(dropout),\n",
        "        # number of hidden neurans, dropout rate for input units\n",
        "        LSTM(units, dropout=dropout),\n",
        "        Dense(3, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "HjuGNT2D4IaI"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train LSTM model\n",
        "lstm_model = create_lstm_model(vocab_size, 200, max_review_length, 32, 0.2)\n",
        "lstm_model.fit(x_train_pad, y_train, epochs=5, batch_size=64, validation_data=(x_validation_pad, y_validation))"
      ],
      "metadata": {
        "id": "B92JANn437wi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e4ea5ba-70e2-453c-e20e-f56f77087155"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "217/217 [==============================] - 195s 889ms/step - loss: 0.6271 - accuracy: 0.7308 - val_loss: 0.4278 - val_accuracy: 0.8349\n",
            "Epoch 2/5\n",
            "217/217 [==============================] - 197s 910ms/step - loss: 0.3549 - accuracy: 0.8684 - val_loss: 0.3728 - val_accuracy: 0.8595\n",
            "Epoch 3/5\n",
            "217/217 [==============================] - 189s 870ms/step - loss: 0.2586 - accuracy: 0.9099 - val_loss: 0.3667 - val_accuracy: 0.8655\n",
            "Epoch 4/5\n",
            "217/217 [==============================] - 202s 930ms/step - loss: 0.2060 - accuracy: 0.9312 - val_loss: 0.3716 - val_accuracy: 0.8727\n",
            "Epoch 5/5\n",
            "217/217 [==============================] - 196s 903ms/step - loss: 0.1702 - accuracy: 0.9426 - val_loss: 0.3962 - val_accuracy: 0.8747\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7d5517508880>"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(lstm_model.summary())"
      ],
      "metadata": {
        "id": "gHg0vaYT9Ohl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89cca2c1-a3bc-428c-cfb4-a86199ee815c"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_5 (Embedding)     (None, 571, 200)          1569200   \n",
            "                                                                 \n",
            " spatial_dropout1d_1 (Spati  (None, 571, 200)          0         \n",
            " alDropout1D)                                                    \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 32)                29824     \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 3)                 99        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1599123 (6.10 MB)\n",
            "Trainable params: 1599123 (6.10 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate LSTM\n",
        "lstm_loss, lstm_accuracy = lstm_model.evaluate(x_validation_pad, y_validation)\n",
        "print(f'LSTM Accuracy: {lstm_accuracy*100:.2f}%')"
      ],
      "metadata": {
        "id": "3JsgFts64FyK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1a825c7-51ec-448f-d122-bb11df729b3c"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "109/109 [==============================] - 9s 80ms/step - loss: 0.3962 - accuracy: 0.8747\n",
            "LSTM Accuracy: 87.47%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " # Bonus:\n"
      ],
      "metadata": {
        "id": "-W3ioyV2RVlY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " ### 1. Input\n",
        " Allow the user to input a new review and predict the result."
      ],
      "metadata": {
        "id": "9s4ihQ5FRbZc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentiments = {0: 'negative', 1: 'neutral', 2: 'positive'}"
      ],
      "metadata": {
        "id": "qJqBz1OhRols"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_review(model, review):\n",
        "  review = preprocessing(review)\n",
        "  review_pad = build_vocab(tokenizer, [review], max_review_length)\n",
        "\n",
        "  y_pred = model.predict(review_pad)\n",
        "  sentiment_pred = np.argmax(y_pred)\n",
        "  return sentiments[sentiment_pred]"
      ],
      "metadata": {
        "id": "jJNZ13GERRY7"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "  review = input('Enter your review (-1 to stop): ')\n",
        "  if review == \"-1\":\n",
        "    break\n",
        "\n",
        "  rnn_prediction = predict_review(rnn_model, review)\n",
        "  print(f'predicted sentiment by RNN model: {rnn_prediction}')\n",
        "\n",
        "  lstm_prediction = predict_review(lstm_model, review)\n",
        "  print(f'predicted sentiment by LSTM model: {lstm_prediction}')\n",
        "  print()"
      ],
      "metadata": {
        "id": "-gLxFQxFRU_M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4346de20-fe3f-4258-c9d1-1faae5835321"
      },
      "execution_count": 89,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your review (-1 to stop): I love it\n",
            "1/1 [==============================] - 0s 346ms/step\n",
            "predicted sentiment by RNN model: positive\n",
            "1/1 [==============================] - 1s 846ms/step\n",
            "predicted sentiment by LSTM model: positive\n",
            "\n",
            "Enter your review (-1 to stop): Bad! so bad\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "predicted sentiment by RNN model: negative\n",
            "1/1 [==============================] - 0s 109ms/step\n",
            "predicted sentiment by LSTM model: negative\n",
            "\n",
            "Enter your review (-1 to stop): It's ok\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "predicted sentiment by RNN model: neutral\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "predicted sentiment by LSTM model: neutral\n",
            "\n",
            "Enter your review (-1 to stop): -1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Report\n",
        "Provide a report that shows model summary of each model and the best\n",
        " hyperparameters for each model (splitting ratio, sequence padding length\n",
        " â€¦ ) with a table showing the accuracy against each parameter (i.e. 80% 20%\n",
        " ratio, 70% 30% ratio, and same for sequence padding length).\n",
        "\n",
        "\n",
        "\n",
        "> Provided as PDF in the submitted folder.\n",
        "\n"
      ],
      "metadata": {
        "id": "wcf9PUWiReEG"
      }
    }
  ]
}