{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Team Members**\n",
        "\n",
        "| Name            | ID       |\n",
        "| :---            | :---     |\n",
        "| Somaya Mohammed | 20200234 |\n",
        "| Mariem Shehab   | 20200844 |\n",
        "| Eman Ibrahim    | 20201038 |\n",
        "| Dina Ahmed      | 20201061 |\n",
        "| Norhan Sayed    | 20201200 |"
      ],
      "metadata": {
        "id": "GM9Ypv4kxxZK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tGiz31c_TFbx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a02c8d1-94d4-4612-a44a-22bb64e77d24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# drive/MyDrive/Colab Notebooks/.."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load the dataset and perform initial data exploration."
      ],
      "metadata": {
        "id": "D72zDkCDTWbA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "gzs57LDIU9Rd"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "email_data = pd.read_csv('drive/MyDrive/Colab Notebooks/Spam_Email_Data.csv')"
      ],
      "metadata": {
        "id": "KXPsiKYRThS8"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Spam Email Data Head: ')\n",
        "print(email_data.head().to_markdown(tablefmt=\"github\", index=False))"
      ],
      "metadata": {
        "id": "qNsSA0LdVUex",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bd7b677-f007-48da-8b22-e617ab5fdfb0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spam Email Data Head: \n",
            "| text                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |   target |\n",
            "|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|----------|\n",
            "| From ilug-admin@linux.ie Mon Jul 29 11:28:02 2002 Return-Path: <ilug-admin@linux.ie> Delivered-To: yyyy@localhost.netnoteinc.com Received: from localhost (localhost [127.0.0.1]) by phobos.labs.netnoteinc.com (Postfix) with ESMTP id A13D94414F for <jm@localhost>; Mon, 29 Jul 2002 06:25:11 -0400 (EDT) Received: from phobos [127.0.0.1] by localhost with IMAP (fetchmail-5.9.0) for jm@localhost (single-drop); Mon, 29 Jul 2002 11:25:11 +0100 (IST) Received: from lugh.tuatha.org (root@lugh.tuatha.org [194.125.145.45]) by dogma.slashnull.org (8.11.6/8.11.6) with ESMTP id g6RHn7i17130 for <jm-ilug@jmason.org>; Sat, 27 Jul 2002 18:49:07 +0100 Received: from lugh (root@localhost [127.0.0.1]) by lugh.tuatha.org (8.9.3/8.9.3) with ESMTP id SAA25016; Sat, 27 Jul 2002 18:45:03 +0100 X-Authentication-Warning: lugh.tuatha.org: Host root@localhost [127.0.0.1] claimed to be lugh Received: from mail1.mail.iol.ie (mail1.mail.iol.ie [194.125.2.192]) by lugh.tuatha.org (8.9.3/8.9.3) with ESMTP id SAA24977 for <ilug@linux.ie>; Sat, 27 Jul 2002 18:44:56 +0100 Received: from dialup125-a.ts551.cwt.esat.net ([193.203.140.125] helo=Hobbiton.cod.ie) by mail1.mail.iol.ie with esmtp (Exim 3.35 #1) id 17YVVF-0001W4-00 for ilug@linux.ie; Sat, 27 Jul 2002 18:37:18 +0100 Received: (from cdaly@localhost) by Hobbiton.cod.ie (8.11.6/8.9.3) id g6RDRoO04681 for ilug@linux.ie; Sat, 27 Jul 2002 14:27:50 +0100 Date: Sat, 27 Jul 2002 14:27:49 +0100 From: Conor Daly <conor.daly@oceanfree.net> To: ILUG main list <ilug@linux.ie> Subject: Re: [ILUG] Architecture crossover trouble w RH7.2 (solved) Message-Id: <20020727142749.B4438@Hobbiton.cod.ie> Mail-Followup-To: ILUG main list <ilug@linux.ie> References: <0D443C91DCE9CD40B1C795BA222A729E018854FA@milexc01.maxtor.com> MIME-Version: 1.0 Content-Type: text/plain; charset=us-ascii Content-Disposition: inline User-Agent: Mutt/1.2.5i In-Reply-To: <0D443C91DCE9CD40B1C795BA222A729E018854FA@milexc01.maxtor.com>; from conor_wynne@maxtor.com on Fri, Jul 26, 2002 at 03:56:22PM +0100 Sender: ilug-admin@linux.ie Errors-To: ilug-admin@linux.ie X-Mailman-Version: 1.1 Precedence: bulk List-Id: Irish Linux Users' Group <ilug.linux.ie> X-Beenthere: ilug@linux.ie On Fri, Jul 26, 2002 at 03:56:22PM +0100 or so it is rumoured hereabouts, Wynne, Conor thought: > Surely it would be faster to save you conf files, install it on the box > again, copy back you confs and voila. > All you car about are the confs as the boite has no DATA right? Yeah, but then I'd have to remember _exactly_ which confs I'd modified and they're not all in /etc either... > Thats what I would do, but you sysadmins have to make life as difficult & > complicated as possible ;--) Yup... In this case, I had two issues. 1. I mirrored the disk to give to someone else to work on but the box he has available has only a P1 or P2 processor. 2. My celeron box has been crashing the backup software so I wanted to try out the backup in a different box to make sure it's hardware related. Again, it's also an interesting exercise... > Have you thought about mirroring the system drives? Might save you serious > hassle down the line. Oh, I'm doing that too. This is going to Africa so I'm aiming for as robust as possible with belt, braces and probably an all-in-one jumpsuit! I'll be mirroring the disk but that is worth only so much (eg. lightning strike taking out the disk(s) or system compromise) I'm also going for a backup to CDR with an automated restore http://www.mondorescue.org . The admin out there wouldn't be able to build the system again if the mobo got fried and the replacement was the wrong arch but an i386 compatible install will mean just dropping in the HD and booting (ish)... Conor -- Conor Daly <conor.daly@oceanfree.net> Domestic Sysadmin :-) --------------------- Faenor.cod.ie 2:32pm up 64 days, 23:49, 0 users, load average: 0.00, 0.00, 0.00 Hobbiton.cod.ie 2:19pm up 7 days, 20:56, 1 user, load average: 0.05, 0.02, 0.00 -- Irish Linux Users' Group: ilug@linux.ie http://www.linux.ie/mailman/listinfo/ilug for (un)subscription information. List maintainer: listmaster@linux.ie |        0 |\n",
            "| From gort44@excite.com Mon Jun 24 17:54:21 2002 Return-Path: gort44@excite.com Delivery-Date: Tue Jun 4 05:31:16 2002 Received: from mandark.labs.netnoteinc.com ([213.105.180.140]) by dogma.slashnull.org (8.11.6/8.11.6) with ESMTP id g544VFO20182 for <jm@jmason.org>; Tue, 4 Jun 2002 05:31:15 +0100 Received: from wi-poli.poli.cl ([200.54.149.34]) by mandark.labs.netnoteinc.com (8.11.2/8.11.2) with SMTP id g544VC729935; Tue, 4 Jun 2002 05:31:13 +0100 Received: from 216.77.61.89 (unverified [218.5.180.148]) by wi-poli.poli.cl (EMWAC SMTPRS 0.83) with SMTP id <B0000918901@wi-poli.poli.cl>; Tue, 04 Jun 2002 00:14:29 -0400 Message-Id: <B0000918901@wi-poli.poli.cl> To: <chrbader@telecom.at> From: \"irese\" <gort44@excite.com> Subject: Cash in on your home equity Date: Tue, 04 Jun 2002 00:18:34 -1600 MIME-Version: 1.0 Content-Type: text/plain; charset=\"Windows-1252\" X-Keywords: Content-Transfer-Encoding: 7bit Mortgage Lenders & Brokers Are Ready to compete for your business. Whether a new home loan is what you seek or to refinance your current home loan at a lower interest rate, we can help! Mortgage rates haven't been this low in years take action now! Refinance your home with us and include all of those pesky credit card bills or use the extra cash for that pool you've always wanted... Where others say NO, we say YES!!! Even if you have been turned down elsewhere, we can help! Easy terms! Our mortgage referral service combines the highest quality loans with the most economical rates and the easiest qualifications! Take just 2 minutes to complete the following form. There is no obligation, all information is kept strictly confidential, and you must be at least 18 years of age. Service is available within the United States only. This service is fast and free. Free information request form: PLEASE VISIT http://builtit4unow.com/pos **************************************************************** Since you have received this message you have either responded to one of our offers in the past or your address has been registered with us. If you wish to \"OPT_OUT\" please visit: http://builtit4unow.com/pos ****************************************************************                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |        1 |\n",
            "| From fork-admin@xent.com Mon Jul 29 11:39:57 2002 Return-Path: <fork-admin@xent.com> Delivered-To: yyyy@localhost.netnoteinc.com Received: from localhost (localhost [127.0.0.1]) by phobos.labs.netnoteinc.com (Postfix) with ESMTP id 0F3F544165 for <jm@localhost>; Mon, 29 Jul 2002 06:34:20 -0400 (EDT) Received: from phobos [127.0.0.1] by localhost with IMAP (fetchmail-5.9.0) for jm@localhost (single-drop); Mon, 29 Jul 2002 11:34:20 +0100 (IST) Received: from webnote.net (mail.webnote.net [193.120.211.219]) by dogma.slashnull.org (8.11.6/8.11.6) with ESMTP id g6RAEOi18890 for <jm@JMASON.ORG>; Sat, 27 Jul 2002 11:14:24 +0100 Received: from xent.com ([64.161.22.236]) by webnote.net (8.9.3/8.9.3) with ESMTP id EAA15163 for <jm@jmason.org>; Sat, 27 Jul 2002 04:01:07 +0100 Received: from lair.xent.com (localhost [127.0.0.1]) by xent.com (Postfix) with ESMTP id 6B8432940A3; Fri, 26 Jul 2002 20:00:08 -0700 (PDT) Delivered-To: fork@spamassassin.taint.org Received: from bolehmail.com (unknown [61.241.232.250]) by xent.com (Postfix) with SMTP id 6EBF629409B; Fri, 26 Jul 2002 19:59:17 -0700 (PDT) Received: from unknown (HELO f64.law4.hottestmale.com) (76.28.45.69) by f64.law4.hottestmale.com with asmtp; 26 Jul 0102 15:08:45 -0500 Received: from unknown (71.24.157.182) by rly-yk04.aolmd.com with local; 26 Jul 0102 10:07:54 +0200 Received: from unknown (HELO smtp013.mail.yahou.com) (143.180.211.131) by rly-yk04.aolmd.com with asmtp; Fri, 26 Jul 0102 12:07:03 +1200 Received: from 46.67.186.19 ([46.67.186.19]) by q4.quickslow.com with asmtp; Sat, 27 Jul 0102 00:06:12 +0300 Reply-To: <5447q67@bolehmail.com> Message-Id: <026a52b71b5e$3662d2e5$0cb01ad7@idrpqw> From: <5447q67@bolehmail.com> To: <fork-request@xent.com>, <fork@spamassassin.taint.org> Subject: Are Your Mortgage Rates The Best They Can Be........ 0922LkVT8-113rFxd3342c-21 MIME-Version: 1.0 Content-Type: text/plain; charset=\"us-ascii\" X-Priority: 3 (Normal) X-Msmail-Priority: Normal X-Mailer: Microsoft Outlook Express 5.50.4522.1200 Importance: Normal Sender: fork-admin@xent.com Errors-To: fork-admin@xent.com X-Beenthere: fork@spamassassin.taint.org X-Mailman-Version: 2.0.11 Precedence: bulk List-Help: <mailto:fork-request@xent.com?subject=help> List-Post: <mailto:fork@spamassassin.taint.org> List-Subscribe: <http://xent.com/mailman/listinfo/fork>, <mailto:fork-request@xent.com?subject=subscribe> List-Id: Friends of Rohit Khare <fork.xent.com> List-Unsubscribe: <http://xent.com/mailman/listinfo/fork>, <mailto:fork-request@xent.com?subject=unsubscribe> List-Archive: <http://xent.com/pipermail/fork/> Date: Fri, 26 Jul 0102 18:03:12 +0900 Content-Transfer-Encoding: 8bit Dear Homeowner, Interest Rates are at their lowest point in 40 years! We help you find the best rate for your situation by matching your needs with hundreds of lenders! Home Improvement, Refinance, Second Mortgage, Home Equity Loans, and much, much more! You're eligible even with less than perfect credit! This service is 100% FREE to home owners and new home buyers without any obligation. Where others say NO, we say YES!!! http://www243.wiildaccess.com Take just 2 minutes to complete the following form. There is no obligation, all information is kept strictly confidential, and you must be at least 18 years of age. Service is available within the United States only. This service is fast and free. http://www243.wiildaccess.com +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ To opt out: http://www243.wiildaccess.com/optout.html 8960ryoE6-752DjSn8958wQDd4-522UPqi8940xzrR4-094LKl46 http://xent.com/mailman/listinfo/fork                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |        1 |\n",
            "| From dcm123@btamail.net.cn Mon Jun 24 17:49:23 2002 Return-Path: dcm123@btamail.net.cn Delivery-Date: Mon Jun 10 04:13:11 2002 Received: from mandark.labs.netnoteinc.com ([213.105.180.140]) by dogma.slashnull.org (8.11.6/8.11.6) with ESMTP id g5A3D8G20808 for <jm@jmason.org>; Mon, 10 Jun 2002 04:13:09 +0100 Received: from tktweb.tktpower.com ([211.90.75.85]) by mandark.labs.netnoteinc.com (8.11.6/8.11.2) with ESMTP id g5A3D6m28913 for <jm@netnoteinc.com>; Mon, 10 Jun 2002 04:13:07 +0100 Message-Id: <200206100313.g5A3D6m28913@mandark.labs.netnoteinc.com> Received: from smtp0115.mail.yahoo.com (dsl-200-67-46-59.prodigy.net.mx [200.67.46.59]) by tktweb.tktpower.com with SMTP (Microsoft Exchange Internet Mail Service Version 5.5.1960.3) id MLV1LZAY; Thu, 6 Jun 2002 12:29:36 +0800 Date: Wed, 5 Jun 2002 21:17:22 -0700 From: \"Rudy Chan\"<dcm123@btamail.net.cn> X-Priority: 3 To: shandatch@netnoir.net Cc: tazzie6813@netnoir.net, troby@netnoir.net, vivranthang@netnoir.net, jm@netnoteinc.com, michael@netnv.net, rich@netnv.net, beam@neto.com, bgarrett@neto.com Subject: Online Approval for $5000 Now MIME-Version: 1.0 X-Keywords: Content-Type: text/html; charset=us-ascii Content-Transfer-Encoding: 7bit <HTML><HEAD><TITLE>Free Card Search</TITLE> <META HTTP-EQUIV=\"Content-Type\" CONTENT=\"text/html; charset=iso-8859-1\"> </HEAD><BODY BGCOLOR=\"#000000\"><div align=\"center\"> <a href=\"http://mbf.%61%66%66%69%6c%69%61%74%65%6e%65%74%74%2e%63%6f%6d/fcard/\"> <IMG SRC=\"http://mbf.%61%66%66%69%6c%69%61%74%65%6e%65%74%74%2e%63%6f%6d/fcard/ad/new_fcard.jpg\" WIDTH=523 HEIGHT=373 border=\"0\"></a> </div><TABLE WIDTH=523 BORDER=0 CELLPADDING=0 CELLSPACING=0 align=\"center\"> <TR><td colspan=7 align=left><br><font color=\"white\" size=\"1\" face=\"arial\"> Sincerely,<BR><B>Your New Offers Staff</B><BR></FONT> <FONT SIZE=\"-2\"><A HREF=\"mailto:montage@btamail.net.cn?subject=Remove\">Remove</A></FONT> </td></tr></TABLE></BODY></HTML>                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |        1 |\n",
            "| From ilug-admin@linux.ie Mon Aug 19 11:02:47 2002 Return-Path: <ilug-admin@linux.ie> Delivered-To: yyyy@localhost.netnoteinc.com Received: from localhost (localhost [127.0.0.1]) by phobos.labs.netnoteinc.com (Postfix) with ESMTP id CB0FC44196 for <jm@localhost>; Mon, 19 Aug 2002 05:54:24 -0400 (EDT) Received: from phobos [127.0.0.1] by localhost with IMAP (fetchmail-5.9.0) for jm@localhost (single-drop); Mon, 19 Aug 2002 10:54:24 +0100 (IST) Received: from lugh.tuatha.org (root@lugh.tuatha.org [194.125.145.45]) by dogma.slashnull.org (8.11.6/8.11.6) with ESMTP id g7HL8j610834 for <jm-ilug@jmason.org>; Sat, 17 Aug 2002 22:08:45 +0100 Received: from lugh (root@localhost [127.0.0.1]) by lugh.tuatha.org (8.9.3/8.9.3) with ESMTP id WAA08700; Sat, 17 Aug 2002 22:07:20 +0100 Received: from hawk.dcu.ie (mail.dcu.ie [136.206.1.5]) by lugh.tuatha.org (8.9.3/8.9.3) with ESMTP id WAA08664 for <ilug@linux.ie>; Sat, 17 Aug 2002 22:07:12 +0100 X-Authentication-Warning: lugh.tuatha.org: Host mail.dcu.ie [136.206.1.5] claimed to be hawk.dcu.ie Received: from prodigy.redbrick.dcu.ie (136.206.15.10) by hawk.dcu.ie (6.0.040) id 3D36BB4A000AD875 for ilug@linux.ie; Sat, 17 Aug 2002 22:07:12 +0100 Received: by prodigy.redbrick.dcu.ie (Postfix, from userid 1023) id 97F48DA4A; Sat, 17 Aug 2002 22:07:11 +0100 (IST) Date: Sat, 17 Aug 2002 22:07:11 +0100 From: Philip Reynolds <phil@redbrick.dcu.ie> To: ilug@linux.ie Subject: Re: [ILUG] expanding a string multiple times Message-Id: <20020817220711.H29114@prodigy.Redbrick.DCU.IE> References: <3D5D27B9.9080009@corvil.com> <20020817100644.GA29167@chewie.compsoc.com> MIME-Version: 1.0 Content-Type: text/plain; charset=us-ascii Content-Disposition: inline User-Agent: Mutt/1.2.5i In-Reply-To: <20020817100644.GA29167@chewie.compsoc.com>; from kor@compsoc.com on Sat, Aug 17, 2002 at 11:06:44AM +0100 Sender: ilug-admin@linux.ie Errors-To: ilug-admin@linux.ie X-Mailman-Version: 1.1 Precedence: bulk List-Id: Irish Linux Users' Group <ilug.linux.ie> X-Beenthere: ilug@linux.ie Kevin O' Riordan's [kor@compsoc.com] 30 lines of wisdom included: > > On Pungenday, the 9th day of Bureaucracy, Padraig Brady confessed: > > How can I repeat a string an arbitrary number > > of times in bash/sed/... > > > > I.E. I'm missing the repeat in the following: > > > > STRING=\"> \" > > NUMBER=3 > > PREFIX=repeat $STRING $NUMBER > > echo $PREFIX > > > > > > > > perl ? > > STRING=\"> \" > NUMBER=3 > PREFIX=`perl -e \"print '$STRING' x $NUMBER;\"` > echo $PREFIX > > I'm pretty sure the bsd 'jot' utility can do this too, but I don't > have it to hand. I didn't think that jot was installed on Linux systems by default, so from the tone of Padraigs mail that's not what he wanted, however, if I'm incorrect (don't have a Linux system to hand) the following is the syntax. jot -b \"string\" 3 Phil. -- Philip Reynolds RFC Networks tel: 01 8832063 www.rfc-networks.ie fax: 01 8832041 -- Irish Linux Users' Group: ilug@linux.ie http://www.linux.ie/mailman/listinfo/ilug for (un)subscription information. List maintainer: listmaster@linux.ie                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |        0 |\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Discover Spam Email Data Information: \\n')\n",
        "print(email_data.info())"
      ],
      "metadata": {
        "id": "qGoEALpGVhxB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c184c047-a9f4-4bd7-ebf6-48dae5f7a6a9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Discover Spam Email Data Information: \n",
            "\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5796 entries, 0 to 5795\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   text    5796 non-null   object\n",
            " 1   target  5796 non-null   int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 90.7+ KB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(email_data.target.value_counts())"
      ],
      "metadata": {
        "id": "507kA4UOVhUV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ac4d52a-a34f-4c01-e300-94dbae3c7768"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "target\n",
            "0    3900\n",
            "1    1896\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing & Features Extraction"
      ],
      "metadata": {
        "id": "3dNNx37ZTsNb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "metadata": {
        "id": "sp85dk_xTtGU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a35bc5f-0566-4d3a-e475-cab7ec5f24ca"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tag import pos_tag"
      ],
      "metadata": {
        "id": "r4Br4X63WxEI"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def text_cleaning(text):\n",
        "    # remove email address\n",
        "    text = re.sub(r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Za-z]{2,}\\b', '', text)\n",
        "    # remove HTML tags\n",
        "    text = re.sub(r'<[^>]+>', ' ', text)\n",
        "    # remove puctuations and numbers\n",
        "    text = re.sub(r'[^A-Za-z\\s]', ' ', text)\n",
        "\n",
        "    return text\n",
        "\n",
        "def preprocessing(text):\n",
        "    # perform text cleaning (removing irrelevant words, symbols, etc.)\n",
        "    clean_text = text_cleaning(text)\n",
        "    # tokenization for lowercase words\n",
        "    text_tokens = word_tokenize(clean_text.lower())\n",
        "    # remove all stopwords\n",
        "    stopwrds = set(stopwords.words('english'))\n",
        "    text_rmstop = [i for i in text_tokens if i not in stopwrds]\n",
        "    # limmatize all words\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    text_lemm = [lemmatizer.lemmatize(w) for w in text_rmstop]\n",
        "    # POS tagging\n",
        "    #pos_tags = pos_tag(text_lemm)\n",
        "    #text_pos = [word for word, pos in pos_tags if pos in ['NN', 'NNS', 'NNP', 'NNPS', 'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ']]\n",
        "\n",
        "    return ' '.join(text_lemm)"
      ],
      "metadata": {
        "id": "heNQoA_OXAkn"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "email_data['text'] = email_data['text'].apply(preprocessing)"
      ],
      "metadata": {
        "id": "ZQzqrx37ccR0"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Spam Email Data Head after Preprocessing: ')\n",
        "print(email_data.head().to_markdown(tablefmt=\"github\", index=False))"
      ],
      "metadata": {
        "id": "wrIRKPV3dMgi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97554ddf-c276-45a3-ca20-1c033d1568db"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spam Email Data Head after Preprocessing: \n",
            "| text                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |   target |\n",
            "|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|----------|\n",
            "| mon jul return path delivered received localhost localhost phobos lab netnoteinc com postfix esmtp id f mon jul edt received phobos localhost imap fetchmail jm localhost single drop mon jul ist received lugh tuatha org dogma slashnull org esmtp id g rhn sat jul received lugh root localhost lugh tuatha org esmtp id saa sat jul x authentication warning lugh tuatha org host root localhost claimed lugh received mail mail iol ie mail mail iol ie lugh tuatha org esmtp id saa sat jul received dialup t cwt esat net helo hobbiton cod ie mail mail iol ie esmtp exim id yvvf w sat jul received cdaly localhost hobbiton cod ie id g rdroo sat jul date sat jul conor daly ilug main list subject ilug architecture crossover trouble w rh solved message id mail followup ilug main list reference mime version content type text plain charset u ascii content disposition inline user agent mutt reply fri jul pm sender error x mailman version precedence bulk list id irish linux user group x beenthere fri jul pm rumoured hereabouts wynne conor thought surely would faster save conf file install box copy back confs voila car confs boite data right yeah remember exactly confs modified etc either thats would sysadmins make life difficult complicated possible yup case two issue mirrored disk give someone else work box available p p processor celeron box crashing backup software wanted try backup different box make sure hardware related also interesting exercise thought mirroring system drive might save serious hassle line oh going africa aiming robust possible belt brace probably one jumpsuit mirroring disk worth much eg lightning strike taking disk system compromise also going backup cdr automated restore http www mondorescue org admin able build system mobo got fried replacement wrong arch compatible install mean dropping hd booting ish conor conor daly domestic sysadmin faenor cod ie pm day user load average hobbiton cod ie pm day user load average irish linux user group http www linux ie mailman listinfo ilug un subscription information list maintainer |        0 |\n",
            "| mon jun return path delivery date tue jun received mandark lab netnoteinc com dogma slashnull org esmtp id g vfo tue jun received wi poli poli cl mandark lab netnoteinc com smtp id g vc tue jun received unverified wi poli poli cl emwac smtprs smtp id tue jun message id irese subject cash home equity date tue jun mime version content type text plain charset window x keywords content transfer encoding bit mortgage lender broker ready compete business whether new home loan seek refinance current home loan lower interest rate help mortgage rate low year take action refinance home u include pesky credit card bill use extra cash pool always wanted others say say yes even turned elsewhere help easy term mortgage referral service combine highest quality loan economical rate easiest qualification take minute complete following form obligation information kept strictly confidential must least year age service available within united state service fast free free information request form please visit http builtit unow com po since received message either responded one offer past address registered u wish opt please visit http builtit unow com po                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |        1 |\n",
            "| mon jul return path delivered received localhost localhost phobos lab netnoteinc com postfix esmtp id f f mon jul edt received phobos localhost imap fetchmail jm localhost single drop mon jul ist received webnote net mail webnote net dogma slashnull org esmtp id g raeoi sat jul received xent com webnote net esmtp id eaa sat jul received lair xent com localhost xent com postfix esmtp id b fri jul pdt delivered received bolehmail com unknown xent com postfix smtp id ebf b fri jul pdt received unknown helo f law hottestmale com f law hottestmale com asmtp jul received unknown rly yk aolmd com local jul received unknown helo smtp mail yahou com rly yk aolmd com asmtp fri jul received q quickslow com asmtp sat jul reply message id subject mortgage rate best lkvt rfxd c mime version content type text plain charset u ascii x priority normal x msmail priority normal x mailer microsoft outlook express importance normal sender error x beenthere x mailman version precedence bulk list help list post list subscribe list id friend rohit khare list unsubscribe list archive date fri jul content transfer encoding bit dear homeowner interest rate lowest point year help find best rate situation matching need hundred lender home improvement refinance second mortgage home equity loan much much eligible even le perfect credit service free home owner new home buyer without obligation others say say yes http www wiildaccess com take minute complete following form obligation information kept strictly confidential must least year age service available within united state service fast free http www wiildaccess com opt http www wiildaccess com optout html ryoe djsn wqdd upqi xzrr lkl http xent com mailman listinfo fork                                                                                                                                                                                                                                                                                                                                                   |        1 |\n",
            "| mon jun return path delivery date mon jun received mandark lab netnoteinc com dogma slashnull org esmtp id g g mon jun received tktweb tktpower com mandark lab netnoteinc com esmtp id g mon jun message id received smtp mail yahoo com dsl prodigy net mx tktweb tktpower com smtp microsoft exchange internet mail service version id mlv lzay thu jun date wed jun rudy chan x priority cc subject online approval mime version x keywords content type text html charset u ascii content transfer encoding bit free card search sincerely new offer staff remove                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |        1 |\n",
            "| mon aug return path delivered received localhost localhost phobos lab netnoteinc com postfix esmtp id cb fc mon aug edt received phobos localhost imap fetchmail jm localhost single drop mon aug ist received lugh tuatha org dogma slashnull org esmtp id g hl j sat aug received lugh root localhost lugh tuatha org esmtp id waa sat aug received hawk dcu ie mail dcu ie lugh tuatha org esmtp id waa sat aug x authentication warning lugh tuatha org host mail dcu ie claimed hawk dcu ie received prodigy redbrick dcu ie hawk dcu ie id bb ad sat aug received prodigy redbrick dcu ie postfix userid id f da sat aug ist date sat aug philip reynolds subject ilug expanding string multiple time message id reference mime version content type text plain charset u ascii content disposition inline user agent mutt reply sat aug sender error x mailman version precedence bulk list id irish linux user group x beenthere kevin riordan line wisdom included pungenday th day bureaucracy padraig brady confessed repeat string arbitrary number time bash sed e missing repeat following string number prefix repeat string number echo prefix perl string number prefix perl e print string x number echo prefix pretty sure bsd jot utility hand think jot installed linux system default tone padraigs mail wanted however incorrect linux system hand following syntax jot b string phil philip reynolds rfc network tel www rfc network ie fax irish linux user group http www linux ie mailman listinfo ilug un subscription information list maintainer                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |        0 |\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Embedding Techniques"
      ],
      "metadata": {
        "id": "59zpLjvsd-Wd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Neural networks based techniques (at least two)\n",
        "\n",
        "*  Word2Vec\n",
        "*  Doc2Vec"
      ],
      "metadata": {
        "id": "41VpUvm2gCR_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "z6OnrpikeHkR"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### word2vec"
      ],
      "metadata": {
        "id": "InnvzE8uQfS4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# creating word2vec model with sentences of word and vector size of 200\n",
        "def word2vec_model(word_of_sent):\n",
        "    model = Word2Vec(sentences=word_of_sent, vector_size=200)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "3nvWw1jJeFK2"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get average embedding for one sentence\n",
        "def get_sentence_vector(model, sentence, vocab):\n",
        "    sentence_vec = np.zeros(200)\n",
        "    count = 0\n",
        "    for word in sentence:\n",
        "        # ensure word is in the vocabulary\n",
        "        if word in vocab:\n",
        "            sentence_vec += model.wv[word]\n",
        "            count += 1\n",
        "    # get average embedding\n",
        "    if count != 0:\n",
        "        sentence_vec /= count\n",
        "\n",
        "    return sentence_vec"
      ],
      "metadata": {
        "id": "7NLf2DQ0eFOW"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split sentence into words\n",
        "def get_word_of_sent(sentences):\n",
        "   word_of_sent = [sentence.split() for sentence in sentences]\n",
        "\n",
        "   return word_of_sent"
      ],
      "metadata": {
        "id": "inLyMYXzQkG8"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train word2vec embedding with training data and get vocabulary and word2vec model with embedding\n",
        "def train_word2vec_embedding(text_data):\n",
        "    word_of_sent = get_word_of_sent(text_data)\n",
        "    w2v_model = word2vec_model(word_of_sent)\n",
        "    vocab = list(w2v_model.wv.key_to_index.keys())\n",
        "\n",
        "    return w2v_model, vocab"
      ],
      "metadata": {
        "id": "fIT6koOXQmLH"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get word2vec embedding for text data either training or testing data\n",
        "def get_word2vec_embedding(text_data, model, vocab):\n",
        "    word_of_sent = get_word_of_sent(text_data)\n",
        "    # get average sentence embedding for each sentence in the text data\n",
        "    embedding = [get_sentence_vector(model, sentence, vocab) for sentence in word_of_sent]\n",
        "\n",
        "    return embedding"
      ],
      "metadata": {
        "id": "O-q7jDIOQm0_"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Doc2Vec"
      ],
      "metadata": {
        "id": "qTvWSR5GXLMd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_Doc2Vec(train_data):\n",
        "  # Prepare TaggedDocument objects for training\n",
        "  documents = [TaggedDocument(words=text.split(), tags=[str(i)]) for i, text in enumerate(train_data)]\n",
        "  # Initialize a Doc2Vec model\n",
        "  doc2vec_model = Doc2Vec(vector_size=200)\n",
        "  # Build the vocabulary from the training data\n",
        "  doc2vec_model.build_vocab(documents)\n",
        "  # Train the Doc2Vec model on the training data\n",
        "  doc2vec_model.train(documents, total_examples=doc2vec_model.corpus_count, epochs=15)\n",
        "\n",
        "  return doc2vec_model"
      ],
      "metadata": {
        "id": "GPWTqcNCbz3E"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_Doc2Vec(doc2vec_model, corpus):\n",
        "  # Generate document vectors for the provided corpus using the trained model\n",
        "  doc_vectors = []\n",
        "  for text in corpus:\n",
        "        # Infer the vector representation of each document in the corpus\n",
        "        doc_vectors.append(doc2vec_model.infer_vector(text.split()))\n",
        "\n",
        "  return doc_vectors"
      ],
      "metadata": {
        "id": "8xN6CehMXMp9"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Techniques that arent based on neural networks (at least two)\n",
        "*   TF-IDF\n",
        "*   Bag of Words\n",
        "\n"
      ],
      "metadata": {
        "id": "SMIcXHjFgDTM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "metadata": {
        "id": "uaR3r2dggLJn"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TF-IDF"
      ],
      "metadata": {
        "id": "ag3ipS1Ua1jg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_TFIDF(train_data):\n",
        "  tfidf_vectorizer = TfidfVectorizer()\n",
        "  tfidf_vectorizer.fit(train_data)\n",
        "  #print(tfidf_vectorizer.get_feature_names_out()[:10])\n",
        "\n",
        "  return tfidf_vectorizer"
      ],
      "metadata": {
        "id": "pFzzkj7Pa6QU"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_TFIDF(tfidf_vectorizer, corpus):\n",
        "  corpus_tfidf = tfidf_vectorizer.transform(corpus)\n",
        "  #print('Shape: ', corpus_tfidf.shape)\n",
        "\n",
        "  return corpus_tfidf"
      ],
      "metadata": {
        "id": "r8uTAfBrhAbg"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bag of Words"
      ],
      "metadata": {
        "id": "VC1bvISxa3aF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_BagOfWords(train_data):\n",
        "  bow_vectorizer = CountVectorizer()\n",
        "  bow_vectorizer.fit(train_data)\n",
        "  #print(bow_vectorizer.get_feature_names_out()[:10])\n",
        "\n",
        "  return bow_vectorizer"
      ],
      "metadata": {
        "id": "aVp7COOZbTPT"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_BagOfWords(bow_vectorizer, corpus):\n",
        "  corpus_bow = bow_vectorizer.transform(corpus)\n",
        "  #print('Shape: ', corpus_bow.shape)\n",
        "\n",
        "  return corpus_bow"
      ],
      "metadata": {
        "id": "kZK4TJgYstB1"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Splitting"
      ],
      "metadata": {
        "id": "wrRyKak8Ttai"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "eKi-sTStTzyP"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(email_data['text'], email_data['target'], train_size=0.6, random_state=42)\n",
        "print('Training Shape: x=', x_train.shape, ' y=', y_train.shape)\n",
        "print('Testing Shape:  x=', x_test.shape,  ' y=', y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KqYpai-9eYZ7",
        "outputId": "d2c10be0-aaa1-46a2-c16d-2ef70964835c"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Shape: x= (3477,)  y= (3477,)\n",
            "Testing Shape:  x= (2319,)  y= (2319,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('y_train:')\n",
        "print(y_train.value_counts())\n",
        "print('y_test:')\n",
        "print(y_test.value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HUzwuc9_TNua",
        "outputId": "0c7ad0cb-0687-4fbc-adf3-fcd0d5a8428d"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y_train:\n",
            "target\n",
            "0    2331\n",
            "1    1146\n",
            "Name: count, dtype: int64\n",
            "y_test:\n",
            "target\n",
            "0    1569\n",
            "1     750\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Training\n",
        "(at least two)\n",
        "\n",
        "*    Logistic Regression\n",
        "*    Decision Tree\n",
        "*    Support Vector Machine"
      ],
      "metadata": {
        "id": "Wo0t3v1OTv4P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC"
      ],
      "metadata": {
        "id": "s38pkutxT0X3"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def LogisticRegression_Model(x_train, y_train):\n",
        "  logistic_model = LogisticRegression(max_iter=1000, random_state=42).fit(x_train, y_train)\n",
        "  return logistic_model"
      ],
      "metadata": {
        "id": "DTiSy6L7lMfJ"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def DecisionTree_Model(x_train, y_train):\n",
        "  decision_tree_model = DecisionTreeClassifier(criterion=\"entropy\", random_state=42).fit(x_train, y_train)\n",
        "  return decision_tree_model"
      ],
      "metadata": {
        "id": "PnxtdffksT2T"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def SVM_Model(x_train, y_train):\n",
        "  svm_model = SVC(random_state=42).fit(x_train, y_train)\n",
        "  return svm_model"
      ],
      "metadata": {
        "id": "iSkJUZhndE4w"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Evaluation"
      ],
      "metadata": {
        "id": "D8BuSOm5T3Ev"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score"
      ],
      "metadata": {
        "id": "jU-SdGYcT4RB"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_result_evaluation(embedding_name, model_name, y_true, y_pred):\n",
        "  precision = precision_score(y_true, y_pred)*100\n",
        "  recall = recall_score(y_true, y_pred)*100\n",
        "  f1 = f1_score(y_true, y_pred)*100\n",
        "  acc = accuracy_score(y_true, y_pred)*100\n",
        "\n",
        "  return {'Text Embedding Technique':embedding_name, 'Classification Model':model_name,\n",
        "          'Accuracy':acc, 'Precision':precision, 'Recall':recall, 'F1-Score':f1}"
      ],
      "metadata": {
        "id": "RWxQYmxjq69-"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating 8 models and evaluate them"
      ],
      "metadata": {
        "id": "7ypqKCOswQdY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TextEmbeddingTechniques = ['Word2Vec','Doc2Vec', 'TF-IDF', 'Bag of Words']\n",
        "ClassificationModels = ['Logistic Regression', 'Decision Tree', 'Support Vector Machine']\n",
        "metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score']"
      ],
      "metadata": {
        "id": "tlC_rt6IDbP4"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getTextEmbeddingTechnique(name, x_train, x_test):\n",
        "  new_train = None\n",
        "  new_test = None\n",
        "  if name == 'TF-IDF':\n",
        "    model = train_TFIDF(x_train)\n",
        "    new_train = get_TFIDF(model, x_train)\n",
        "    new_test = get_TFIDF(model, x_test)\n",
        "    #print(\"Maximum TF-IDF value:\", new_train.max(), new_test.max())\n",
        "    #print(\"Minimum TF-IDF value:\", new_train.min(), new_test.min())\n",
        "  elif name == 'Bag of Words':\n",
        "    model = train_BagOfWords(x_train)\n",
        "    new_train = get_BagOfWords(model, x_train)\n",
        "    new_test = get_BagOfWords(model, x_test)\n",
        "    #print(\"Maximum BOW value:\", new_train.max(), new_test.max())\n",
        "    #print(\"Minimum BOW value:\", new_train.min(), new_test.min())\n",
        "  elif name == 'Word2Vec':\n",
        "    model, vocab = train_word2vec_embedding(x_train)\n",
        "    new_train = get_word2vec_embedding(x_train, model, vocab)\n",
        "    new_test = get_word2vec_embedding(x_test, model, vocab)\n",
        "  elif name == 'Doc2Vec':\n",
        "    model = train_Doc2Vec(x_train)\n",
        "    new_train = get_Doc2Vec(model, x_train)\n",
        "    new_test = get_Doc2Vec(model, x_test)\n",
        "\n",
        "  return new_train, new_test"
      ],
      "metadata": {
        "id": "QJa2wmtQD5uZ"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getClassificationModel(name, x_train, y_train):\n",
        "  if name == 'Logistic Regression':\n",
        "      return LogisticRegression_Model(x_train, y_train)\n",
        "  elif name == 'Decision Tree':\n",
        "      return DecisionTree_Model(x_train, y_train)\n",
        "  elif name == 'Support Vector Machine':\n",
        "      return SVM_Model(x_train, y_train)"
      ],
      "metadata": {
        "id": "5oLNod4iFjIE"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_evaluate_models(x_train, x_test, y_train, y_test):\n",
        "  evaluation_results = [] # to save evaluation results of all models\n",
        "\n",
        "  # loop over all text embedding techniques\n",
        "  for technique_name in TextEmbeddingTechniques:\n",
        "      new_x_train, new_x_test = getTextEmbeddingTechnique(technique_name, x_train, x_test)\n",
        "      # loop over all classification models\n",
        "      for model_name in ClassificationModels:\n",
        "          model = getClassificationModel(model_name, new_x_train, y_train)\n",
        "          y_pred = model.predict(new_x_test)\n",
        "          # evaluate current model and save its results\n",
        "          current_eval = model_result_evaluation(technique_name, model_name, y_test, y_pred)\n",
        "          evaluation_results.append(current_eval)\n",
        "          #print(current_eval)\n",
        "\n",
        "  return evaluation_results"
      ],
      "metadata": {
        "id": "x4BspEfSwaCc"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation_results = create_evaluate_models(x_train, x_test, y_train, y_test)"
      ],
      "metadata": {
        "id": "dejhWgL5wg3Q"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_results = pd.DataFrame(evaluation_results)\n",
        "\n",
        "print('All Models Performance Results (based on testing set):')\n",
        "print('------------------------------------------------------')\n",
        "print(final_results.to_markdown(tablefmt=\"github\", index=False))"
      ],
      "metadata": {
        "id": "hZ37Hom9zO3x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7a13e04-c1bb-463b-ef99-a1632888e445"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All Models Performance Results (based on testing set):\n",
            "------------------------------------------------------\n",
            "| Text Embedding Technique   | Classification Model   |   Accuracy |   Precision |   Recall |   F1-Score |\n",
            "|----------------------------|------------------------|------------|-------------|----------|------------|\n",
            "| Word2Vec                   | Logistic Regression    |    98.5339 |     98.9071 |  96.5333 |    97.7058 |\n",
            "| Word2Vec                   | Decision Tree          |    97.1971 |     95.1252 |  96.2667 |    95.6925 |\n",
            "| Word2Vec                   | Support Vector Machine |    98.4476 |     99.0385 |  96.1333 |    97.5643 |\n",
            "| Doc2Vec                    | Logistic Regression    |    97.1539 |     97.2376 |  93.8667 |    95.5224 |\n",
            "| Doc2Vec                    | Decision Tree          |    86.2009 |     77.9221 |  80      |    78.9474 |\n",
            "| Doc2Vec                    | Support Vector Machine |    97.3696 |     97.7809 |  94      |    95.8532 |\n",
            "| TF-IDF                     | Logistic Regression    |    98.6201 |     99.5856 |  96.1333 |    97.829  |\n",
            "| TF-IDF                     | Decision Tree          |    97.4989 |     95.6464 |  96.6667 |    96.1538 |\n",
            "| TF-IDF                     | Support Vector Machine |    99.2238 |     99.7283 |  97.8667 |    98.7887 |\n",
            "| Bag of Words               | Logistic Regression    |    99.4394 |     99.8647 |  98.4    |    99.1269 |\n",
            "| Bag of Words               | Decision Tree          |    98.1026 |     97.832  |  96.2667 |    97.043  |\n",
            "| Bag of Words               | Support Vector Machine |    98.7495 |     99.4513 |  96.6667 |    98.0392 |\n"
          ]
        }
      ]
    }
  ]
}